
Importing Libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
from sklearn import metrics
from sklearn import tree
import warnings
warnings.filterwarnings('ignore')
Load the dataset
crop_df=pd.read_csv('Final Dataset/crop_recommendation.csv')
crop_df.head()
N	P	K	temperature	humidity	ph	rainfall	label
0	90	42	43	20.879744	82.002744	6.502985	202.935536	rice
1	85	58	41	21.770462	80.319644	7.038096	226.655537	rice
2	60	55	44	23.004459	82.320763	7.840207	263.964248	rice
3	74	35	40	26.491096	80.158363	6.980401	242.864034	rice
4	78	42	42	20.130175	81.604873	7.628473	262.717340	rice
crop_df.tail()
N	P	K	temperature	humidity	ph	rainfall	label
2195	107	34	32	26.774637	66.413269	6.780064	177.774507	coffee
2196	99	15	27	27.417112	56.636362	6.086922	127.924610	coffee
2197	118	33	30	24.131797	67.225123	6.362608	173.322839	coffee
2198	117	32	34	26.272418	52.127394	6.758793	127.175293	coffee
2199	104	18	30	23.603016	60.396475	6.779833	140.937041	coffee
Data Visualization
Univariate Analysis
sns.displot(crop_df["P"])

sns.displot(crop_df["N"])

sns.displot(crop_df["K"])

sns.histplot(y=crop_df.temperature) 

sns.boxplot(crop_df.rainfall) 

Bi-Variate Analysis
sns.barplot(x=crop_df.rainfall,y=crop_df.label)

sns.pointplot(y=crop_df.label,x=crop_df.rainfall)

Multi-Variate Analysis
sns.pairplot(data=crop_df)

Perform descriptive statistics on the dataset.
crop_df.info()
RangeIndex: 2200 entries, 0 to 2199
Data columns (total 8 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   N            2200 non-null   int64  
 1   P            2200 non-null   int64  
 2   K            2200 non-null   int64  
 3   temperature  2200 non-null   float64
 4   humidity     2200 non-null   float64
 5   ph           2200 non-null   float64
 6   rainfall     2200 non-null   float64
 7   label        2200 non-null   object 
dtypes: float64(4), int64(3), object(1)
memory usage: 137.6+ KB
crop_df.describe()
N	P	K	temperature	humidity	ph	rainfall
count	2200.000000	2200.000000	2200.000000	2200.000000	2200.000000	2200.000000	2200.000000
mean	50.551818	53.362727	48.149091	25.616244	71.481779	6.469480	103.463655
std	36.917334	32.985883	50.647931	5.063749	22.263812	0.773938	54.958389
min	0.000000	5.000000	5.000000	8.825675	14.258040	3.504752	20.211267
25%	21.000000	28.000000	20.000000	22.769375	60.261953	5.971693	64.551686
50%	37.000000	51.000000	32.000000	25.598693	80.473146	6.425045	94.867624
75%	84.250000	68.000000	49.000000	28.561654	89.948771	6.923643	124.267508
max	140.000000	145.000000	205.000000	43.675493	99.981876	9.935091	298.560117
crop_df["label"].value_counts()
rice           100
maize          100
jute           100
cotton         100
coconut        100
papaya         100
orange         100
apple          100
muskmelon      100
watermelon     100
grapes         100
mango          100
banana         100
pomegranate    100
lentil         100
blackgram      100
mungbean       100
mothbeans      100
pigeonpeas     100
kidneybeans    100
chickpea       100
coffee         100
Name: label, dtype: int64
crop_df.dtypes
N                int64
P                int64
K                int64
temperature    float64
humidity       float64
ph             float64
rainfall       float64
label           object
dtype: object
crop_df.corr()
N	P	K	temperature	humidity	ph	rainfall
N	1.000000	-0.231460	-0.140512	0.026504	0.190688	0.096683	0.059020
P	-0.231460	1.000000	0.736232	-0.127541	-0.118734	-0.138019	-0.063839
K	-0.140512	0.736232	1.000000	-0.160387	0.190859	-0.169503	-0.053461
temperature	0.026504	-0.127541	-0.160387	1.000000	0.205320	-0.017795	-0.030084
humidity	0.190688	-0.118734	0.190859	0.205320	1.000000	-0.008483	0.094423
ph	0.096683	-0.138019	-0.169503	-0.017795	-0.008483	1.000000	-0.109069
rainfall	0.059020	-0.063839	-0.053461	-0.030084	0.094423	-0.109069	1.000000
Check for Missing values and deal with them.
crop_df.isnull().sum()
N              0
P              0
K              0
temperature    0
humidity       0
ph             0
rainfall       0
label          0
dtype: int64
s=crop_df.corr()
s
N	P	K	temperature	humidity	ph	rainfall
N	1.000000	-0.231460	-0.140512	0.026504	0.190688	0.096683	0.059020
P	-0.231460	1.000000	0.736232	-0.127541	-0.118734	-0.138019	-0.063839
K	-0.140512	0.736232	1.000000	-0.160387	0.190859	-0.169503	-0.053461
temperature	0.026504	-0.127541	-0.160387	1.000000	0.205320	-0.017795	-0.030084
humidity	0.190688	-0.118734	0.190859	0.205320	1.000000	-0.008483	0.094423
ph	0.096683	-0.138019	-0.169503	-0.017795	-0.008483	1.000000	-0.109069
rainfall	0.059020	-0.063839	-0.053461	-0.030084	0.094423	-0.109069	1.000000
sns.heatmap(s,annot=True)

Split the data into dependent and independent variables.
feature=crop_df[['N','P','K','temperature','humidity','ph','rainfall']]
target=crop_df['label']
acc=[]
model=[]
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(feature,target,test_size=0.2,random_state=2)
X_train
N	P	K	temperature	humidity	ph	rainfall
1936	113	38	25	22.000851	79.472710	7.388266	90.422242
610	28	35	22	29.530376	86.733460	7.156563	59.872321
372	11	61	21	18.623288	23.024103	5.532101	135.337803
1559	29	139	205	23.641424	93.744615	6.155939	116.691218
1500	24	128	196	22.750888	90.694892	5.521467	110.431786
...	...	...	...	...	...	...	...
1071	105	88	54	25.787498	84.511942	6.020445	114.200546
433	27	71	23	23.453790	46.487148	7.109598	150.871220
674	23	39	22	29.256493	81.979522	6.864839	42.024833
1099	117	81	53	29.507046	78.205856	5.507642	98.125658
1608	39	24	14	30.554726	90.903438	7.189260	106.071198
1760 rows × 7 columns

y_train
1936         cotton
610        mungbean
372     kidneybeans
1559          apple
1500          apple
           ...     
1071         banana
433      pigeonpeas
674        mungbean
1099         banana
1608         orange
Name: label, Length: 1760, dtype: object
X_test
N	P	K	temperature	humidity	ph	rainfall
2121	83	21	28	25.567483	60.492446	7.466901	190.225784
960	1	27	36	23.985988	93.342366	5.684995	104.991282
952	23	5	44	21.207254	94.263047	7.163005	107.566080
1958	116	52	19	22.942767	75.371706	6.114526	67.080226
681	6	37	17	28.086572	80.350059	6.760694	38.144768
...	...	...	...	...	...	...	...
1684	7	17	10	10.164313	91.223210	6.465913	106.362551
1477	86	18	45	28.965866	90.718329	6.566759	22.258381
851	6	64	23	23.335652	67.404607	7.065264	36.186787
370	37	56	25	22.055923	19.603793	5.774755	126.726537
2010	89	53	44	24.886928	71.917115	7.319735	150.249867
440 rows × 7 columns

y_test
2121         coffee
960     pomegranate
952     pomegranate
1958         cotton
681        mungbean
           ...     
1684         orange
1477      muskmelon
851          lentil
370     kidneybeans
2010           jute
Name: label, Length: 440, dtype: object
Build the Model
Decision Tree
from sklearn.tree import DecisionTreeClassifier
DecisionTree=DecisionTreeClassifier(criterion='entropy',max_depth=5,random_state=2)
DecisionTree.fit(X_train,y_train)
predicted=DecisionTree.predict(X_test)
x=metrics.accuracy_score(y_test,predicted)
acc.append(x)
model.append('Decision Tree')
print("Accuracy[Decision Tree]:",x*100)
Accuracy[Decision Tree]: 90.0
print(classification_report(y_test,predicted))
              precision    recall  f1-score   support

       apple       1.00      1.00      1.00        13
      banana       1.00      1.00      1.00        17
   blackgram       0.59      1.00      0.74        16
    chickpea       1.00      1.00      1.00        21
     coconut       0.91      1.00      0.95        21
      coffee       1.00      1.00      1.00        22
      cotton       1.00      1.00      1.00        20
      grapes       1.00      1.00      1.00        18
        jute       0.74      0.93      0.83        28
 kidneybeans       0.00      0.00      0.00        14
      lentil       0.68      1.00      0.81        23
       maize       1.00      1.00      1.00        21
       mango       1.00      1.00      1.00        26
   mothbeans       0.00      0.00      0.00        19
    mungbean       1.00      1.00      1.00        24
   muskmelon       1.00      1.00      1.00        23
      orange       1.00      1.00      1.00        29
      papaya       1.00      0.84      0.91        19
  pigeonpeas       0.62      1.00      0.77        18
 pomegranate       1.00      1.00      1.00        17
        rice       1.00      0.62      0.77        16
  watermelon       1.00      1.00      1.00        15

    accuracy                           0.90       440
   macro avg       0.84      0.88      0.85       440
weighted avg       0.86      0.90      0.87       440

from sklearn.model_selection import cross_val_score
score=cross_val_score(DecisionTree,feature,target,cv=5)
score
array([0.93636364, 0.90909091, 0.91818182, 0.87045455, 0.93636364])
Naive Bayes
from sklearn.naive_bayes import GaussianNB
Naive_Bayes=GaussianNB()
Naive_Bayes.fit(X_train,y_train)
predicted=Naive_Bayes.predict(X_test)
x=metrics.accuracy_score(y_test,predicted)
acc.append(x)
model.append('Naive Bayes')
print("Accuracy[Naive Bayes]:",x*100)
Accuracy[Naive Bayes]: 99.0909090909091
print(classification_report(y_test,predicted))
              precision    recall  f1-score   support

       apple       1.00      1.00      1.00        13
      banana       1.00      1.00      1.00        17
   blackgram       1.00      1.00      1.00        16
    chickpea       1.00      1.00      1.00        21
     coconut       1.00      1.00      1.00        21
      coffee       1.00      1.00      1.00        22
      cotton       1.00      1.00      1.00        20
      grapes       1.00      1.00      1.00        18
        jute       0.88      1.00      0.93        28
 kidneybeans       1.00      1.00      1.00        14
      lentil       1.00      1.00      1.00        23
       maize       1.00      1.00      1.00        21
       mango       1.00      1.00      1.00        26
   mothbeans       1.00      1.00      1.00        19
    mungbean       1.00      1.00      1.00        24
   muskmelon       1.00      1.00      1.00        23
      orange       1.00      1.00      1.00        29
      papaya       1.00      1.00      1.00        19
  pigeonpeas       1.00      1.00      1.00        18
 pomegranate       1.00      1.00      1.00        17
        rice       1.00      0.75      0.86        16
  watermelon       1.00      1.00      1.00        15

    accuracy                           0.99       440
   macro avg       0.99      0.99      0.99       440
weighted avg       0.99      0.99      0.99       440

score=cross_val_score(Naive_Bayes,feature,target,cv=5)
score
array([0.99772727, 0.99545455, 0.99545455, 0.99545455, 0.99090909])
Logistic Regression
from sklearn.linear_model import LogisticRegression
logreg=LogisticRegression()
logreg.fit(X_train,y_train)
predicted=logreg.predict(X_test)
x=metrics.accuracy_score(y_test,predicted)
acc.append(x)
model.append('Logistic Regression')
print("Accuracy[Logistic Regression]:",x*100)
Accuracy[Logistic Regression]: 95.22727272727273
print(classification_report(y_test,predicted))
              precision    recall  f1-score   support

       apple       1.00      1.00      1.00        13
      banana       1.00      1.00      1.00        17
   blackgram       0.86      0.75      0.80        16
    chickpea       1.00      1.00      1.00        21
     coconut       1.00      1.00      1.00        21
      coffee       1.00      1.00      1.00        22
      cotton       0.86      0.90      0.88        20
      grapes       1.00      1.00      1.00        18
        jute       0.84      0.93      0.88        28
 kidneybeans       1.00      1.00      1.00        14
      lentil       0.88      1.00      0.94        23
       maize       0.90      0.86      0.88        21
       mango       0.96      1.00      0.98        26
   mothbeans       0.84      0.84      0.84        19
    mungbean       1.00      0.96      0.98        24
   muskmelon       1.00      1.00      1.00        23
      orange       1.00      1.00      1.00        29
      papaya       1.00      0.95      0.97        19
  pigeonpeas       1.00      1.00      1.00        18
 pomegranate       1.00      1.00      1.00        17
        rice       0.85      0.69      0.76        16
  watermelon       1.00      1.00      1.00        15

    accuracy                           0.95       440
   macro avg       0.95      0.95      0.95       440
weighted avg       0.95      0.95      0.95       440

score=cross_val_score(logreg,feature,target,cv=5)
score
array([0.95      , 0.96590909, 0.94772727, 0.96818182, 0.94318182])
Support Vector Machine
from sklearn.svm import SVC
SVM=SVC(gamma='auto')
SVM.fit(X_train,y_train)
predicted=SVM.predict(X_test)
x=metrics.accuracy_score(y_test,predicted)
acc.append(x)
model.append('SVM')
print('Accuracy[SVM]:',x*100)
Accuracy[SVM]: 10.681818181818182
print(classification_report(y_test,predicted))
              precision    recall  f1-score   support

       apple       1.00      0.23      0.38        13
      banana       1.00      0.24      0.38        17
   blackgram       1.00      0.19      0.32        16
    chickpea       1.00      0.05      0.09        21
     coconut       1.00      0.05      0.09        21
      coffee       0.00      0.00      0.00        22
      cotton       1.00      0.05      0.10        20
      grapes       1.00      0.06      0.11        18
        jute       1.00      0.07      0.13        28
 kidneybeans       0.03      1.00      0.07        14
      lentil       0.00      0.00      0.00        23
       maize       0.00      0.00      0.00        21
       mango       0.00      0.00      0.00        26
   mothbeans       0.00      0.00      0.00        19
    mungbean       1.00      0.12      0.22        24
   muskmelon       1.00      0.30      0.47        23
      orange       1.00      0.03      0.07        29
      papaya       1.00      0.05      0.10        19
  pigeonpeas       0.00      0.00      0.00        18
 pomegranate       1.00      0.12      0.21        17
        rice       0.50      0.06      0.11        16
  watermelon       1.00      0.13      0.24        15

    accuracy                           0.11       440
   macro avg       0.66      0.13      0.14       440
weighted avg       0.66      0.11      0.13       440

score=cross_val_score(SVM,feature,target,cv=5)
score
array([0.27727273, 0.28863636, 0.29090909, 0.275     , 0.26818182])
Random Forest
from sklearn.ensemble import RandomForestClassifier
RF=RandomForestClassifier(n_estimators=29,criterion='entropy',random_state=0)
RF.fit(X_train,y_train)
predicted=RF.predict(X_test)
x=metrics.accuracy_score(y_test,predicted)
acc.append(x)
model.append("Random Forest")
print("Accuracy[Random Forest]:",x*100)
Accuracy[Random Forest]: 99.31818181818181
print(classification_report(y_test,predicted))
              precision    recall  f1-score   support

       apple       1.00      1.00      1.00        13
      banana       1.00      1.00      1.00        17
   blackgram       0.94      1.00      0.97        16
    chickpea       1.00      1.00      1.00        21
     coconut       1.00      1.00      1.00        21
      coffee       1.00      1.00      1.00        22
      cotton       1.00      1.00      1.00        20
      grapes       1.00      1.00      1.00        18
        jute       0.93      1.00      0.97        28
 kidneybeans       1.00      1.00      1.00        14
      lentil       1.00      1.00      1.00        23
       maize       1.00      1.00      1.00        21
       mango       1.00      1.00      1.00        26
   mothbeans       1.00      0.95      0.97        19
    mungbean       1.00      1.00      1.00        24
   muskmelon       1.00      1.00      1.00        23
      orange       1.00      1.00      1.00        29
      papaya       1.00      1.00      1.00        19
  pigeonpeas       1.00      1.00      1.00        18
 pomegranate       1.00      1.00      1.00        17
        rice       1.00      0.88      0.93        16
  watermelon       1.00      1.00      1.00        15

    accuracy                           0.99       440
   macro avg       0.99      0.99      0.99       440
weighted avg       0.99      0.99      0.99       440

score=cross_val_score(RF,feature,target,cv=5)
score
array([0.99772727, 0.99090909, 0.99545455, 0.99318182, 0.98636364])
Evaluating Accuracy
data={'Algorithms':model,'Accuracy':acc}
AC=pd.DataFrame(data)
AC
Algorithms	Accuracy
0	Decision Tree	0.900000
1	Naive Bayes	0.990909
2	Logistic Regression	0.952273
3	SVM	0.106818
4	Random Forest	0.993182
plt.figure(figsize=[12,8],dpi=100)
plt.title('Accuracy Comparison')
plt.xlabel('Accuracy')
plt.ylabel('Algorithms')
sns.barplot(x=acc,y=model,palette='dark')

Save the Best Model
import pickle
file_name='Model/crop_recommender.pkl'
pkl=open(file_name,'wb')
pickle.dump(RF,pkl)
pkl.close()
 
